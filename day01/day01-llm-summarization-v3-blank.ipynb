{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 1 - Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 Models\n",
    "\n",
    "The <code>flan-t5</code> is a Text-To-Text Transfer Transformer (T5) that is capable of performing zero-shot NLP task such as summary, simple reasoninig, answering questions, etc. \n",
    "\n",
    "Some T5 models from Huggingface\n",
    "- [<code>google/flan-t5-base</code>](https://huggingface.co/google/flan-t5-base)\n",
    "- [<code>google/flan-t5-small</code>](https://huggingface.co/google/flan-t5-small)\n",
    "- [<code>google/flan-t5-xl</code>](https://huggingface.co/google/flan-t5-xl)\n",
    "- [<code>google/flan-t5-xxl</code>](https://huggingface.co/google/flan-t5-xxl) - full model\n",
    "\n",
    "Complete list of [T5 models](https://huggingface.co/models?search=google/flan) on Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/flan-t5-base'\n",
    "#model_name = 'sshleifer/distilbart-cnn-12-6'\n",
    "# (\"Write a summary based on this article:\\n\\n{text}\", \"{summary}\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load tokenizer and model\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 768)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the model\n",
    "print(model)\n",
    "# the Embedding is the input size of the model (row, element)\n",
    "# in this case 32k vocab size, 768 embedding size\n",
    "# 32128 x 768 = 2.46M parameters\n",
    "# there's SelfAttention layers to consider the count (q,k,v, o-output)\n",
    "\n",
    "# lm_head is the attention head, spills out the next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" \n",
    "Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way,\n",
    "I doubted if I should ever come back.\n",
    "\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I—\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" \n",
    "When a traveler in north central Massachusetts takes the wrong fork\n",
    "at the junction of the Aylesbury pike just beyond Dean's Corners he\n",
    "comes upon a lonely and curious country. The ground gets higher, and\n",
    "the brier-bordered stone walls press closer and closer against the ruts\n",
    "of the dusty, curving road. The trees of the frequent forest belts\n",
    "seem too large, and the wild weeds, brambles, and grasses attain a\n",
    "luxuriance not often found in settled regions. At the same time the\n",
    "planted fields appear singularly few and barren; while the sparsely\n",
    "scattered houses wear a surprizing uniform aspect of age, squalor, and\n",
    "dilapidation. Without knowing why, one hesitates to ask directions\n",
    "from the gnarled, solitary figures spied now and then on crumbling\n",
    "doorsteps or in the sloping, rock-strewn meadows. Those figures are\n",
    "so silent and furtive that one feels somehow confronted by forbidden\n",
    "things, with which it would be better to have nothing to do. When a\n",
    "rise in the road brings the mountains in view above the deep woods,\n",
    "the feeling of strange uneasiness is increased. The summits are too\n",
    "rounded and symmetrical to give a sense of comfort and naturalness, and\n",
    "sometimes the sky silhouettes with especial clearness the queer circles\n",
    "of tall stone pillars with which most of them are crowned.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a summary based on this article:\n",
      "\n",
      " \n",
      "When a traveler in north central Massachusetts takes the wrong fork\n",
      "at the junction of the Aylesbury pike just beyond Dean's Corners he\n",
      "comes upon a lonely and curious country. The ground gets higher, and\n",
      "the brier-bordered stone walls press closer and closer against the ruts\n",
      "of the dusty, curving road. The trees of the frequent forest belts\n",
      "seem too large, and the wild weeds, brambles, and grasses attain a\n",
      "luxuriance not often found in settled regions. At the same time the\n",
      "planted fields appear singularly few and barren; while the sparsely\n",
      "scattered houses wear a surprizing uniform aspect of age, squalor, and\n",
      "dilapidation. Without knowing why, one hesitates to ask directions\n",
      "from the gnarled, solitary figures spied now and then on crumbling\n",
      "doorsteps or in the sloping, rock-strewn meadows. Those figures are\n",
      "so silent and furtive that one feels somehow confronted by forbidden\n",
      "things, with which it would be better to have nothing to do. When a\n",
      "rise in the road brings the mountains in view above the deep woods,\n",
      "the feeling of strange uneasiness is increased. The summits are too\n",
      "rounded and symmetrical to give a sense of comfort and naturalness, and\n",
      "sometimes the sky silhouettes with especial clearness the queer circles\n",
      "of tall stone pillars with which most of them are crowned.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a prompt\n",
    "prompt = f\"Write a summary based on this article:\\n\\n{text}\"\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8733,     3,     9,  9251,     3,   390,    30,    48,  1108,    10,\n",
      "           366,     3,     9,  1111,    49,    16,  3457,  2069,  9777,  1217,\n",
      "             8,  1786,    21,   157,    44,     8, 23704,    13,     8,    71,\n",
      "            63,   965,  7165,  2816,  1050,   131,  1909, 12738,    31,     7,\n",
      "         15143,     7,     3,    88,   639,  1286,     3,     9, 23633,    11,\n",
      "          9865,   684,     5,    37,  1591,  2347,  1146,     6,    11,     8,\n",
      "             3,  2160,    49,    18, 24678,    15,    26,  3372,  4205,  2785,\n",
      "          4645,    11,  4645,   581,     8,     3,  6830,     7,    13,     8,\n",
      "          5784,    63,     6,  5495,  3745,  1373,     5,    37,  3124,    13,\n",
      "             8,  8325,  5827,  6782,     7,  1727,   396,   508,     6,    11,\n",
      "             8,  3645,     3,  8578,     7,     6,  3858,    51,  2296,     7,\n",
      "             6,    11,  5956,    15,     7, 14568,     3,     9,     3,  8387,\n",
      "           459,   663,    59,   557,   435,    16, 10166,  6266,     5,   486,\n",
      "             8,   337,    97,     8, 15359,  4120,  2385, 22166,   120,   360,\n",
      "            11, 18595,    29,   117,   298,     8, 14144,     7,    15,   120,\n",
      "         20193,  4790,  2112,     3,     9,   244,  2246,  8128,  7117,  2663,\n",
      "            13,  1246,     6,     3,     7, 11433,   127,     6,    11,  1227,\n",
      "           521, 12417,   257,     5,  6404,  4265,   572,     6,    80, 10888,\n",
      "             7,    12,   987,  7943,    45,     8,     3, 11260,    52,  1361,\n",
      "             6,     3,     7, 28028,  5638,     3,     7,  8082,    26,   230,\n",
      "            11,   258,    30, 22854,    53, 26929,     7,    42,    16,     8,\n",
      "             3,     7,  8745,    53,     6,  2480,    18,     7,   929,   210,\n",
      "            29,   140,     9, 15198,     7,     5,     3,  3405,  5638,    33,\n",
      "            78, 11237,    11,  4223,  3268,    24,    80,  4227,  9296, 11230,\n",
      "            15,    26,    57, 29387,   378,     6,    28,    84,    34,   133,\n",
      "            36,   394,    12,    43,  1327,    12,   103,     5,   366,     3,\n",
      "             9,  3098,    16,     8,  1373,  3200,     8,  8022,    16,   903,\n",
      "           756,     8,  1659,  1679,     7,     6,     8,  1829,    13,  6765,\n",
      "           245,     9,     7,  6096,    19,  1936,     5,    37, 13385,     7,\n",
      "            33,   396,     3, 12279,    11,     3, 23596,   138,    12,   428,\n",
      "             3,     9,  1254,    13,  2115,    11,   793,   655,     6,    11,\n",
      "          1664,     8,  5796, 19561,     7,    28,     3,    15, 17434,   964,\n",
      "           655,     8,   238,    49, 15162,    13,  5065,  3372,     3, 12851,\n",
      "             7,    28,    84,   167,    13,   135,    33,     3, 31657,     5,\n",
      "             3,     1]])\n"
     ]
    }
   ],
   "source": [
    "# TODO: tokenize the text\n",
    "prompt_enc = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "print(prompt_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "config = GenerationConfig(\n",
    "    max_new_tokens=100, # how many new tokens other than the prompt\n",
    "    early_stopping=True, # stop when you hit the eos token\n",
    "    do_sample=True, # use sampling\n",
    "    temperature=0.5, # randomness of output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,    37,  3283,    13,    48,   684,    19,    78,     3,   122,\n",
      "         14351,    63,    24,    25,  3384,    24,    25,    54,    31,    17,\n",
      "           199,    68,    36,     3,     7, 20348,    57,     8,  2790,    13,\n",
      "             8,  1679,     7,     5,     1]])\n"
     ]
    }
   ],
   "source": [
    "# TODO: summarize paragraph with model\n",
    "result_enc = model.generate(prompt_enc, generation_config=config)\n",
    "\n",
    "print(result_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The landscape of this country is so gloomy that you realize that you can't help but be smitten by the beauty of the woods.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Decode the token\n",
    "result = tokenizer.decode(result_enc[0], skip_special_tokens=True)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# notice the output is capped without generation_config, so we need to set it to get the full summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature is a value between 0 to infinity\n",
    "# increases or decreases the randomness of the. completion by sharpening or flatenning the probablity distribution (if lower means making probabilities bigger)\n",
    "# 0 = greedy decoding, always pick the most likely next token\n",
    "# 1 = default sampling\n",
    "# >1 = more random, less likely tokens are more likely to be picked\n",
    "\n",
    "# add in sampling so that you dont always get the same output (it influences the completion by not always taking the top-k tokens)\n",
    "# top-k means reduces the choices to k, recalculate probability with software\n",
    "# top-p smallest group of choices whose cumulative probailities is at least p (e.g. atleast 80% must be met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "config = GenerationConfig(\n",
    "    max_new_tokens=100, # how many new tokens other than the prompt\n",
    "    early_stopping=True, # stop when you hit the eos token\n",
    "    do_sample=True, # use sampling\n",
    "    temperature=5.0, # randomness of output\n",
    ")\n",
    "\n",
    "result_enc = model.generate(prompt_enc, generation_config=config)\n",
    "result = tokenizer.decode(result_enc[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You miss little and every corner it will mean to your absence—snurneying into quiet rural homes filled only with empty walls with the helplessly uncompriminy sight (I'y being bold, it'S easy here in those winter temperatures of summer); even those places made just after fall already get less predictable because even they come to look good and stay pretty -- they also keep being mysterious for quite unknown. If anything its quite unopferrneyd,\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuall perform one decoding step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the decoder and the lm_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feed the encoded prompt directly to the decode by passing the encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the size of the tensor from the decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feed the decoder output into the lm_head\n",
    "# TODO: Print the shape of the lm_head output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the next predicted (highest/greedy) token of the prompt. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: decode the token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get all the predicted next token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print each token individually\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 Models\n",
    "\n",
    "The <code>flan-t5</code> is a Text-To-Text Transfer Transformer (T5) that is capable of performing zero-shot NLP task such as summary, simple reasoninig, answering questions, etc. \n",
    "\n",
    "Some T5 models from Huggingface\n",
    "- [<code>google/flan-t5-base</code>](https://huggingface.co/google/flan-t5-base)\n",
    "- [<code>google/flan-t5-small</code>](https://huggingface.co/google/flan-t5-small)\n",
    "- [<code>google/flan-t5-xl</code>](https://huggingface.co/google/flan-t5-xl)\n",
    "- [<code>google/flan-t5-xxl</code>](https://huggingface.co/google/flan-t5-xxl) - full model\n",
    "\n",
    "Complete list of [T5 models](https://huggingface.co/models?search=google/flan) on Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" \n",
    "When a traveler in north central Massachusetts takes the wrong fork\n",
    "at the junction of the Aylesbury pike just beyond Dean's Corners he\n",
    "comes upon a lonely and curious country. The ground gets higher, and\n",
    "the brier-bordered stone walls press closer and closer against the ruts\n",
    "of the dusty, curving road. The trees of the frequent forest belts\n",
    "seem too large, and the wild weeds, brambles, and grasses attain a\n",
    "luxuriance not often found in settled regions. At the same time the\n",
    "planted fields appear singularly few and barren; while the sparsely\n",
    "scattered houses wear a surprizing uniform aspect of age, squalor, and\n",
    "dilapidation. Without knowing why, one hesitates to ask directions\n",
    "from the gnarled, solitary figures spied now and then on crumbling\n",
    "doorsteps or in the sloping, rock-strewn meadows. Those figures are\n",
    "so silent and furtive that one feels somehow confronted by forbidden\n",
    "things, with which it would be better to have nothing to do. When a\n",
    "rise in the road brings the mountains in view above the deep woods,\n",
    "the feeling of strange uneasiness is increased. The summits are too\n",
    "rounded and symmetrical to give a sense of comfort and naturalness, and\n",
    "sometimes the sky silhouettes with especial clearness the queer circles\n",
    "of tall stone pillars with which most of them are crowned.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "Write a short summary for this article: {text}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Perform summarization with google/flan-t5-base model, configure the model's output logits\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
