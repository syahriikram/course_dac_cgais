{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Article Retrieval Tool using Open AI\n",
    "\n",
    "This section defines a simple Python function, `get_article`, that uses the `wikipedia` Python package to search for and retrieve the content of a Wikipedia article based on a search term. This function will be used as a tool for the agent to fetch up-to-date information from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "def get_article(search_term):\n",
    "    results = wikipedia.search(search_term)\n",
    "    first_result = results[0]\n",
    "    page = wikipedia.page(first_result, auto_suggest=False)\n",
    "    return page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Fetching and Previewing Wikipedia Articles\n",
    "\n",
    "Here, we demonstrate how to use the `get_article` function to retrieve and preview the content of Wikipedia articles for various search terms, such as \"Avengers: Doomsday\", \"Nezha 2\", \"History of Malaysia\", and \"Iron Man\". Only a preview of the article content is printed for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article(\"Avengers: Doomsday\")\n",
    "# print(article[:1000]) \n",
    "# article is very long, so let's just print a preview\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "article = get_article(\"Avengers: Doomsday\")\n",
    "html_content = f\"\"\"\n",
    "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #007bff;\">\n",
    "    <h3 style=\"color: #007bff; margin-top: 0;\">Avengers: Doomsday Answer Preview</h3>\n",
    "    <p style=\"line-height: 1.6; text-align: justify;\">{article[:1000]}...</p>\n",
    "    <small style=\"color: #6c757d;\">(Showing first 1000 characters)</small>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article(\"Nezha 2\")\n",
    "print(article[:500]) # article is very long, so let's just print a preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article(\"History of Malaysia\")\n",
    "print(article[:3000]) #article is super long so let's just print a preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article(\"Iron Man\")\n",
    "print(article[:1000]) #article is super long so let's just print a preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Schema Definition for OpenAI Function Calling\n",
    "\n",
    "This cell defines a tool schema dictionary, `article_search_tool`, which describes the Wikipedia retrieval tool in a format compatible with OpenAI's function calling API. The schema includes:\n",
    "\n",
    "- **Tool type**: Specifies this as a \"function\" for OpenAI's API\n",
    "- **Function name**: Identifies the tool as \"get_article\"\n",
    "- **Description**: Explains the tool's purpose for retrieving Wikipedia articles\n",
    "- **Parameters**: Defines the input structure with required search terms\n",
    "- **Required fields**: Ensures proper parameter validation\n",
    "\n",
    "This schema enables GPT models to understand when and how to use the Wikipedia article retrieval functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_search_tool = {\n",
    "    \"type\": \"function\",  # This is required for OpenAI\n",
    "    \"function\": {\n",
    "        \"name\": \"get_article\",\n",
    "        \"description\": \"A tool to retrieve an up to date Wikipedia article.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"search_term\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The search term to find a wikipedia article by title\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"search_term\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up OpenAI Client and Making a Tool-Use Request\n",
    "\n",
    "This section initializes the OpenAI API client and demonstrates a complete tool-use workflow with GPT-4o. The implementation includes:\n",
    "\n",
    "- **Client Initialization**: Setting up the OpenAI client with proper authentication\n",
    "- **Tool Schema Definition**: Defining the Wikipedia article retrieval tool for OpenAI's function calling API\n",
    "- **Two-Stage API Calls**: First call to request tool use, second call to provide final answer\n",
    "- **Tool Execution**: Implementing the actual Wikipedia article retrieval functionality\n",
    "- **Beautiful Display**: Using IPython HTML to present results with professional styling\n",
    "\n",
    "The workflow handles questions that require external information (e.g., \"What is the box office for Nezha 2?\") by automatically detecting when tool use is needed, executing the Wikipedia search, and presenting the results in an elegant, formatted display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML\n",
    "import wikipedia\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "def display_final_answer(question, answer, tool_used=None, search_term=None):\n",
    "    \"\"\"\n",
    "    Display the final answer with beautiful HTML styling\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"\n",
    "    <div style=\"\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "        max-width: 800px;\n",
    "        margin: 20px auto;\n",
    "        background: white;\n",
    "        border-radius: 15px;\n",
    "        box-shadow: 0 10px 30px rgba(0,0,0,0.15);\n",
    "        overflow: hidden;\n",
    "    \">\n",
    "        <!-- Header -->\n",
    "        <div style=\"\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 25px;\n",
    "            text-align: center;\n",
    "        \">\n",
    "            <h1 style=\"margin: 0; font-size: 24px;\">ü§ñ AI Response</h1>\n",
    "            <p style=\"margin: 10px 0 0 0; opacity: 0.9;\">Powered by GPT-4o with Tool Assistance</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Question -->\n",
    "        <div style=\"padding: 20px 25px 10px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">‚ùì Question</h3>\n",
    "            <div style=\"\n",
    "                background: #f8f9fa;\n",
    "                padding: 15px;\n",
    "                border-radius: 8px;\n",
    "                margin-top: 10px;\n",
    "                border-left: 4px solid #3498db;\n",
    "            \">\n",
    "                <p style=\"margin: 0; font-size: 16px; color: #34495e;\">{question}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add tool usage info if available\n",
    "    if tool_used and search_term:\n",
    "        html_content += f\"\"\"\n",
    "        <!-- Tool Usage -->\n",
    "        <div style=\"padding: 10px 25px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">üîß Tool Used</h3>\n",
    "            <div style=\"\n",
    "                background: #fff3cd;\n",
    "                padding: 15px;\n",
    "                border-radius: 8px;\n",
    "                margin-top: 10px;\n",
    "                border-left: 4px solid #f39c12;\n",
    "            \">\n",
    "                <p style=\"margin: 0; font-weight: 600; color: #856404;\">\n",
    "                    <strong>Tool:</strong> {tool_used}<br>\n",
    "                    <strong>Search Term:</strong> {search_term}\n",
    "                </p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # Add the answer\n",
    "    html_content += f\"\"\"\n",
    "        <!-- Answer -->\n",
    "        <div style=\"padding: 10px 25px 25px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">üí¨ Answer</h3>\n",
    "            <div style=\"\n",
    "                background: #d4edda;\n",
    "                padding: 20px;\n",
    "                border-radius: 8px;\n",
    "                margin-top: 10px;\n",
    "                border-left: 4px solid #28a745;\n",
    "            \">\n",
    "                <p style=\"\n",
    "                    margin: 0; \n",
    "                    font-size: 16px; \n",
    "                    line-height: 1.8; \n",
    "                    color: #155724;\n",
    "                    text-align: justify;\n",
    "                \">{answer}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Footer -->\n",
    "        <div style=\"\n",
    "            background: #2c3e50;\n",
    "            color: white;\n",
    "            padding: 15px 25px;\n",
    "            text-align: center;\n",
    "            font-size: 12px;\n",
    "        \">\n",
    "            <p style=\"margin: 0;\">Generated with OpenAI GPT-4o and IPython HTML Display</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))\n",
    "\n",
    "# Define the Wikipedia article retrieval function\n",
    "def get_article(search_term):\n",
    "    try:\n",
    "        results = wikipedia.search(search_term)\n",
    "        if results:\n",
    "            first_result = results[0]\n",
    "            page = wikipedia.page(first_result, auto_suggest=False)\n",
    "            return page.content\n",
    "        else:\n",
    "            return f\"No Wikipedia article found for '{search_term}'\"\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving article: {str(e)}\"\n",
    "\n",
    "# Define the tool schema for OpenAI\n",
    "article_search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_article\",\n",
    "        \"description\": \"A tool to retrieve an up to date Wikipedia article.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"search_term\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The search term to find a wikipedia article by title\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"search_term\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Your question\n",
    "question = \"What is the box office for Nezha 2\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "# First API call - model will request tool use\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    "    tools=[article_search_tool]\n",
    ")\n",
    "\n",
    "tool_used = None\n",
    "search_term = None\n",
    "\n",
    "# Check if the model wants to use a tool\n",
    "if response.choices[0].message.tool_calls:\n",
    "    # Get the tool call\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_args = eval(tool_call.function.arguments)\n",
    "    \n",
    "    # Add the assistant's message to the conversation\n",
    "    messages.append(response.choices[0].message)\n",
    "    \n",
    "    # Execute the tool\n",
    "    if tool_name == \"get_article\":\n",
    "        search_term = tool_args[\"search_term\"]\n",
    "        tool_used = \"Wikipedia Article Search\"\n",
    "        print(f\"üîç Searching Wikipedia for: {search_term}\")\n",
    "        tool_result = get_article(search_term)\n",
    "        \n",
    "        # Add the tool result to the conversation\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": tool_result\n",
    "        })\n",
    "        \n",
    "        # Second API call - model will provide the final answer\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "\n",
    "# Get the final answer\n",
    "final_answer = response.choices[0].message.content\n",
    "\n",
    "# Display with beautiful HTML\n",
    "display_final_answer(question, final_answer, tool_used, search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending the Assistant's Tool Use to the Conversation\n",
    "\n",
    "This cell appends the assistant's tool use response to the ongoing conversation history, preparing for the next step in the agentic interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For OpenAI APIs, use this:\n",
    "messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Tool Use Information\n",
    "\n",
    "This section extracts the tool name and input parameters from the model's tool use response, so that the tool can be called programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More robust way to get tool use information for OpenAI\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_input = eval(tool_call.function.arguments)\n",
    "    print(\"Tool name: \", tool_name)\n",
    "    print(\"Tool input: \", tool_input)\n",
    "else:\n",
    "    print(\"No tool calls found in the response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the Tool and Returning Results\n",
    "\n",
    "Here, the code checks if the model requested the Wikipedia tool, executes the tool with the provided input, and prints a preview of the Wikipedia article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, extract the tool information from the OpenAI response\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_input = eval(tool_call.function.arguments)\n",
    "    print(\"Tool name: \", tool_name)\n",
    "    print(\"Tool input: \", tool_input)\n",
    "    \n",
    "    # Now execute the tool\n",
    "    if tool_name == \"get_article\":\n",
    "        search_term = tool_input[\"search_term\"]\n",
    "        wiki_result = get_article(search_term)\n",
    "        print(f\"üîç Searching Wikipedia for: {search_term}\")\n",
    "        print(\"üìÑ WIKIPEDIA PAGE CONTENT:\")\n",
    "        print(wiki_result[:500]) #just printing a small bit of the article because it's so long\n",
    "else:\n",
    "    print(\"No tool calls found in the response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Tool Result Message\n",
    "\n",
    "This cell shows how to construct a message containing the tool result, formatted according to the agentic API's expectations, so it can be sent back to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the tool result to the conversation\n",
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": tool_result\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending the Tool Result to the Conversation\n",
    "\n",
    "The tool result message is appended to the conversation history, allowing the agent to use the tool's output in its next response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tool information from OpenAI response\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_input = eval(tool_call.function.arguments)\n",
    "    \n",
    "    # Execute the tool\n",
    "    if tool_name == \"get_article\":\n",
    "        search_term = tool_input[\"search_term\"]\n",
    "        wiki_result = get_article(search_term)\n",
    "        \n",
    "        # Create tool response for OpenAI\n",
    "        tool_response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": wiki_result\n",
    "        }\n",
    "        \n",
    "        # Add to messages\n",
    "        messages.append(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if tool_response exists\n",
    "if 'tool_response' in locals():\n",
    "    print(\"Tool response:\", tool_response)\n",
    "else:\n",
    "    print(\"Tool response not defined. Make sure you've run the tool execution code first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make sure you have the API response with tool calls\n",
    "if response.choices[0].message.tool_calls:\n",
    "    # Step 2: Extract tool information\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_input = eval(tool_call.function.arguments)\n",
    "    \n",
    "    # Step 3: Execute the tool to get wiki_result\n",
    "    if tool_name == \"get_article\":\n",
    "        search_term = tool_input[\"search_term\"]\n",
    "        wiki_result = get_article(search_term)  # This creates wiki_result\n",
    "        \n",
    "        # Step 4: Now create the tool_response\n",
    "        tool_response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": wiki_result\n",
    "        }\n",
    "        \n",
    "        # Step 5: Append to messages\n",
    "        messages.append(tool_response)\n",
    "        \n",
    "        print(\"Tool response added successfully!\")\n",
    "else:\n",
    "    print(\"No tool calls found in the response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make sure you have all the required components defined\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "# 1. Check if client is defined\n",
    "print(\"Client defined:\", client is not None)\n",
    "\n",
    "# 2. Check if messages is defined and has content\n",
    "print(\"Messages:\", messages)\n",
    "\n",
    "# 3. Check if article_search_tool is defined\n",
    "print(\"Article search tool:\", article_search_tool)\n",
    "\n",
    "# 4. Now try the API call with error handling\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        tools=[article_search_tool]\n",
    "    )\n",
    "    print(\"API call successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Follow-up: Final Answer Generation\n",
    "\n",
    "This section sends the updated conversation (including the tool result) back to the model, prompting it to generate a final answer that incorporates the information retrieved from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check and clean up the messages array\n",
    "print(\"Current messages:\", messages)\n",
    "\n",
    "# Reset messages to a clean state\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the box office for Nezha 2\"}]\n",
    "\n",
    "# Now run the complete workflow with proper message structure\n",
    "try:\n",
    "    # First API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        tools=[article_search_tool]\n",
    "    )\n",
    "    \n",
    "    # Handle tool calls with proper message structure\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        # Add assistant's message with tool_calls FIRST\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"tool_calls\": response.choices[0].message.tool_calls\n",
    "        })\n",
    "        \n",
    "        # Execute tool\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        tool_name = tool_call.function.name\n",
    "        tool_input = eval(tool_call.function.arguments)\n",
    "        \n",
    "        if tool_name == \"get_article\":\n",
    "            search_term = tool_input[\"search_term\"]\n",
    "            wiki_result = get_article(search_term)\n",
    "            \n",
    "            # Add tool response AFTER the assistant message\n",
    "            tool_response = {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": wiki_result\n",
    "            }\n",
    "            messages.append(tool_response)\n",
    "            \n",
    "            # Final API call (without tools parameter)\n",
    "            follow_up_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            \n",
    "            # Get final answer\n",
    "            final_answer = follow_up_response.choices[0].message.content\n",
    "            print(\"Final Answer:\", final_answer)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"Messages at error:\", messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic Tool Use: Full Question-Answering Loop\n",
    "\n",
    "This cell defines a reusable function, `answer_question`, that demonstrates the full agentic tool-use loop: sending a question to the model, detecting tool use, executing the tool, sending the result, and printing the model's final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question):\n",
    "    \"\"\"\n",
    "    Answer a question using OpenAI GPT-4o with tool assistance\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    \n",
    "    try:\n",
    "        # First API call\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=1000,\n",
    "            tools=[article_search_tool]\n",
    "        )\n",
    "        \n",
    "        # Handle tool calls\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            # Add assistant's message with tool_calls\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response.choices[0].message.content,\n",
    "                \"tool_calls\": response.choices[0].message.tool_calls\n",
    "            })\n",
    "            \n",
    "            # Execute tool\n",
    "            tool_call = response.choices[0].message.tool_calls[0]\n",
    "            tool_name = tool_call.function.name\n",
    "            tool_input = eval(tool_call.function.arguments)\n",
    "            \n",
    "            if tool_name == \"get_article\":\n",
    "                search_term = tool_input[\"search_term\"]\n",
    "                print(f\"üîç Searching Wikipedia for: {search_term}\")\n",
    "                wiki_result = get_article(search_term)\n",
    "                \n",
    "                # Add tool response\n",
    "                tool_response = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": wiki_result\n",
    "                }\n",
    "                messages.append(tool_response)\n",
    "                \n",
    "                # Final API call\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=messages,\n",
    "                    max_tokens=1000\n",
    "                )\n",
    "        \n",
    "        # Get final answer\n",
    "        final_answer = response.choices[0].message.content\n",
    "        return final_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Now you can call it\n",
    "result = answer_question(\"What are the names of all the known Avengers films that will be released in the Marvel Cinematic Universe?\")\n",
    "print(\"Answer:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_answer_with_html(question, answer):\n",
    "    \"\"\"\n",
    "    Display the question and answer with beautiful HTML styling\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"\n",
    "    <div style=\"\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "        max-width: 800px;\n",
    "        margin: 20px auto;\n",
    "        background: white;\n",
    "        border-radius: 15px;\n",
    "        box-shadow: 0 10px 30px rgba(0,0,0,0.15);\n",
    "        overflow: hidden;\n",
    "    \">\n",
    "        <!-- Header -->\n",
    "        <div style=\"\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 25px;\n",
    "            text-align: center;\n",
    "        \">\n",
    "            <h1 style=\"margin: 0; font-size: 24px;\">ü§ñ AI Response</h1>\n",
    "            <p style=\"margin: 10px 0 0 0; opacity: 0.9;\">Powered by GPT-4o with Tool Assistance</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Question -->\n",
    "        <div style=\"padding: 20px 25px 10px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">‚ùì Question</h3>\n",
    "            <div style=\"\n",
    "                background: #f8f9fa;\n",
    "                padding: 15px;\n",
    "                border-radius: 8px;\n",
    "                margin-top: 10px;\n",
    "                border-left: 4px solid #3498db;\n",
    "            \">\n",
    "                <p style=\"margin: 0; font-size: 16px; color: #34495e;\">{question}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Answer -->\n",
    "        <div style=\"padding: 10px 25px 25px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">üí¨ Answer</h3>\n",
    "            <div style=\"\n",
    "                background: #d4edda;\n",
    "                padding: 20px;\n",
    "                border-radius: 8px;\n",
    "                margin-top: 10px;\n",
    "                border-left: 4px solid #28a745;\n",
    "            \">\n",
    "                <p style=\"\n",
    "                    margin: 0; \n",
    "                    font-size: 16px; \n",
    "                    line-height: 1.8; \n",
    "                    color: #155724;\n",
    "                    text-align: justify;\n",
    "                \">{answer}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Footer -->\n",
    "        <div style=\"\n",
    "            background: #2c3e50;\n",
    "            color: white;\n",
    "            padding: 15px 25px;\n",
    "            text-align: center;\n",
    "            font-size: 12px;\n",
    "        \">\n",
    "            <p style=\"margin: 0;\">Generated with OpenAI GPT-4o and IPython HTML Display</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))\n",
    "\n",
    "def answer_question(question):\n",
    "    \"\"\"\n",
    "    Answer a question using OpenAI GPT-4o with tool assistance\n",
    "    \"\"\"\n",
    "    # Start with a clean messages array\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    \n",
    "    try:\n",
    "        # First API call\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=1000,\n",
    "            tools=[article_search_tool]\n",
    "        )\n",
    "        \n",
    "        # Handle tool calls\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            # Add assistant's message with tool_calls\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response.choices[0].message.content,\n",
    "                \"tool_calls\": response.choices[0].message.tool_calls\n",
    "            })\n",
    "            \n",
    "            # Execute ALL tool calls (not just the first one)\n",
    "            for tool_call in response.choices[0].message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_input = eval(tool_call.function.arguments)\n",
    "                \n",
    "                if tool_name == \"get_article\":\n",
    "                    search_term = tool_input[\"search_term\"]\n",
    "                    print(f\"üîç Searching Wikipedia for: {search_term}\")\n",
    "                    wiki_result = get_article(search_term)\n",
    "                    \n",
    "                    # Add tool response for THIS specific tool call\n",
    "                    tool_response = {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,  # Use the specific tool_call.id\n",
    "                        \"content\": wiki_result\n",
    "                    }\n",
    "                    messages.append(tool_response)\n",
    "            \n",
    "            # Final API call\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "        \n",
    "        # Get final answer\n",
    "        final_answer = response.choices[0].message.content\n",
    "        \n",
    "        # Display with beautiful HTML\n",
    "        display_answer_with_html(question, final_answer)\n",
    "        \n",
    "        return final_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error: {str(e)}\"\n",
    "        display_answer_with_html(question, error_msg)\n",
    "        return error_msg\n",
    "\n",
    "# Test the function with HTML display\n",
    "result = answer_question(\"What is quantum computing?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain_env)",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
